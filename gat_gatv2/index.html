<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>GAT&amp;GATv2 - Tabuless</title><meta name="Description" content="个人阅读笔记"><meta property="og:title" content="GAT&amp;GATv2" />
<meta property="og:description" content="GAT1 graph attention network，用于解决图结构数据的分类问题。主要思想是通过计算与其相邻的节点的关系（self-attention机制）计算每个节点的" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tabuless.github.io/gat_gatv2/" /><meta property="og:image" content="https://tabuless.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-07T22:45:00+08:00" />
<meta property="article:modified_time" content="2022-03-08T09:56:08+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://tabuless.github.io/logo.png"/>

<meta name="twitter:title" content="GAT&amp;GATv2"/>
<meta name="twitter:description" content="GAT1 graph attention network，用于解决图结构数据的分类问题。主要思想是通过计算与其相邻的节点的关系（self-attention机制）计算每个节点的"/>
<meta name="application-name" content="tabuless">
<meta name="apple-mobile-web-app-title" content="tabuless"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://tabuless.github.io/gat_gatv2/" /><link rel="prev" href="https://tabuless.github.io/%E6%97%B6%E5%BA%8F%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%BC%E8%BF%B0/" /><link rel="next" href="https://tabuless.github.io/tgat/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "GAT\u0026GATv2",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/tabuless.github.io\/gat_gatv2\/"
        },"image": ["https:\/\/tabuless.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "图神经网络","wordcount":  2721 ,
        "url": "https:\/\/tabuless.github.io\/gat_gatv2\/","datePublished": "2022-03-07T22:45:00+08:00","dateModified": "2022-03-08T09:56:08+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "tabuless","logo": "https:\/\/tabuless.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "tabuless"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Tabuless">Tabuless&#39; Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/friends/"> 友链 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/tabuless" title="GitHub" rel="noopener noreffer" target="_blank">  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Tabuless">Tabuless&#39; Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/friends/" title="">友链</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/tabuless" title="GitHub" rel="noopener noreffer" target="_blank"></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">GAT&amp;GATv2</h1><h2 class="single-subtitle">graph attention newtwork</h2><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://tabuless.github.io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>tabuless</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"><i class="far fa-folder fa-fw"></i>知识图谱</a>&nbsp;<a href="/categories/%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B/"><i class="far fa-folder fa-fw"></i>基本模型</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-03-07">2022-03-07</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2721 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#gat1">GAT</a>
      <ul>
        <li><a href="#graph-attention-layer">graph attention layer</a>
          <ul>
            <li><a href="#attention的计算">attention的计算</a></li>
            <li><a href="#加入激活函数">加入激活函数</a></li>
          </ul>
        </li>
        <li><a href="#gat最后一层">GAT最后一层</a></li>
        <li><a href="#gat和gcn的比较">GAT和GCN的比较</a></li>
      </ul>
    </li>
    <li><a href="#gatv22">GATv2</a>
      <ul>
        <li>
          <ul>
            <li><a href="#静态动态注意力staticdynamic-attention">静态/动态注意力（static/dynamic attention）</a></li>
            <li><a href="#gatv2的动态注意力">GATv2的动态注意力</a></li>
            <li><a href="#如何选择gat与gatv2">如何选择GAT与GATv2</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="gat1">GAT<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h2>
<p>graph attention network，用于解决图结构数据的分类问题。主要思想是通过计算与其相邻的节点的关系（self-attention机制）计算每个节点的表示方法。</p>
<p>attention机制的优点：</p>
<ul>
<li>不同相邻节点对可以并行操作</li>
<li>通过不同的权重表示不同的度（degree）的节点</li>
<li>inductive learning</li>
</ul>
<blockquote>
<p><strong>inductive</strong>:如果训练数据不包括测试集，如经典样本独立的supervised learning</p>
<p><strong>transductive</strong>:如果训练数据包括测试集（无标注），如样本间有连接的LPA算法</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="GAT.png"
        data-srcset="/gat_gatv2/GAT.png, GAT.png 1.5x, /gat_gatv2/GAT.png 2x"
        data-sizes="auto"
        alt="/gat_gatv2/GAT.png"
        title="GAT的attention与multi-head" /></p>
<h3 id="graph-attention-layer">graph attention layer</h3>
<p>GAT每层成为graph attention layer：</p>
<p>单层输入、输出为节点的特征（feature）：</p>
<div>$$
输入：\mathbf{h} = \{ \overrightarrow{h_1}, \overrightarrow{h_2}, \dots, \overrightarrow{h_N} \}, \overrightarrow{h_i} \in \mathbb{R}^F\\
输出：\mathbf{h'} = \{ \overrightarrow{h'_1}, \overrightarrow{h'_2}, \dots, \overrightarrow{h'_N} \},\overrightarrow{h'_i} \in \mathbb{R}^{F'}
$$</div>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>F/F'</td>
<td>每个节点的输入/输出特征</td>
</tr>
<tr>
<td>h/h'</td>
<td>输入/输出节点的特征集合</td>
</tr>
<tr>
<td>N</td>
<td>节点个数</td>
</tr>
</tbody>
</table>
<h4 id="attention的计算">attention的计算</h4>
<p>首先计算attention系数：</p>
<div>$$
e_{ij} = a(\mathbf{W} \overrightarrow{h_i}, \mathbf{W} \overrightarrow{h_j})，j\in \mathcal{N}_i
$$</div>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>$e_{ij}$</td>
<td>节点i与j之间的attention系数（attention coefficient）</td>
</tr>
<tr>
<td>a</td>
<td>$\mathbb{R}^{F'}\times \mathbb{R}^{F'}\rightarrow \mathbb{R}$ 的attention机制，表示节点j对i的重要性，最简单的a是一个单层全连接神经网络（FFN）</td>
</tr>
<tr>
<td>$\mathcal{N}_i$</td>
<td>i的相邻节点</td>
</tr>
</tbody>
</table>
<blockquote>
<p>$\mathcal{N}_i$是attention引入图的一个核心概念，因为不相邻的节点没有直接联系</p>
</blockquote>
<p>论文中论文中使用$\overrightarrow{a}\in \mathbb{R}^{2F'}$，并且应用<code>LeakyReLU</code>：</p>
<div>$$
e_{ij} = \text{LeakyReLU} \Big( \overrightarrow{\mathbf{a}}^\top \Big[\mathbf{W} \overrightarrow{h_i}|| \mathbf{W} \overrightarrow{h_j} \Big] \Big)
$$</div>
其中`||`是concat操作。
<p>为了让attention 系数在不同节点之间有可比较性，进行一次softmax：</p>
<div>$$
\alpha_{ij} = \text{softmax}_j(e_{ij}) = \frac{\exp(e_{ij})}{\sum_{j \in \mathcal{N}_i} \exp(e_{ij})}
$$</div>
上述的$\alpha_{ij}$指的就是节点i与节点j之间的attention。
<h4 id="加入激活函数">加入激活函数</h4>
<p>对于多头的注意力机制，假如有$K$个头，则第$k$头的输出$\overrightarrow{h'^k_i}$为：</p>
<div>$$
\overrightarrow{h'^k_i} =\sigma \Big (\sum_{j \in \mathcal{N}_i} \alpha^k_{ij} \mathbf{W}^k \overrightarrow{h_j} \Big )
$$</div>
最后通过一个concat操作得到最终的多头attention的单层输出：
<div>$$
\overrightarrow{h'_i} = \Bigg\Vert_{k=1}^{K} \overrightarrow{h'^k_i}
$$</div>
<h3 id="gat最后一层">GAT最后一层</h3>
<p>如果在最后一层的话multi-head的concat操作不再敏感，一般不会concat，而是对每个head取平均，把非线性层（softmax或者sigmoid）放在最后进行操作：</p>
<div>$$
\overrightarrow{h_i'} =\sigma \Big (\frac{1}{K}\sum_{k=1}^{K}\sum_{j \in \mathcal{N}_i} \alpha^k_{ij} \mathbf{W}^k \overrightarrow{h_j} \Big )
$$</div>
<h3 id="gat和gcn的比较">GAT和GCN的比较</h3>
<ul>
<li>计算高效，所有的相邻节点之间的attention可以并行计算</li>
<li>给不同相邻节点间赋值不同的重要性</li>
</ul>
<p>代码示例：<a href="https://nn.labml.ai/graphs/gat/index.html" target="_blank" rel="noopener noreffer">https://nn.labml.ai/graphs/gat/index.html</a></p>
<h2 id="gatv22">GATv2<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></h2>
<p>在GAT中，每个节点通过使用自己的representation作为query，根据其邻居节点更新其representation。通过让每个节点计算邻居节点之间的加权平均得到最相关的节点，产生了很多典型的average-pooling和max-pooling。</p>
<p>但是GATv2的作者认为GAT没有真正计算真正的注意力，GAT的注意力被定义为静态注意力（static attention），真正的注意力被他们称之为<em>动态</em>注意力（<em>dynamic</em> attention）。</p>
<p>通过修改GAT中的操作顺序，GATv2实现了一个通用的近似注意函数，因此严格来说比GAT更强大。</p>
<h4 id="静态动态注意力staticdynamic-attention">静态/动态注意力（static/dynamic attention）</h4>
<p>GAT中，对于任意的节点（query），attention函数是关于邻接节点（key）单调（monotonic）的：对于一组keys，如果不同的query对这组keys进行attention，得到的attention分数排名不变，那么这个attention函数就是静态的。如下图所示。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="GATv2.png"
        data-srcset="/gat_gatv2/GATv2.png, GATv2.png 1.5x, /gat_gatv2/GATv2.png 2x"
        data-sizes="auto"
        alt="/gat_gatv2/GATv2.png"
        title="GATv2-static attention" /></p>
<p><strong>静态注意力的定义</strong>：已知一个key的集合$\mathbb{K}={k_1,k_2,&hellip;,k_n}\subset \mathbb{R}^d$与query集合$\mathbb{Q}={q_1,q_2,&hellip;,q_m}\subset \mathbb{R}^d$，对于一个打分函数族$\mathcal{F}\subseteq (\mathbb{R}^d\times\mathbb{R}^d \rightarrow \mathbb{R})$，如果对于$\forall f\in\mathcal{F}$，存在一个“最高分数”的key $j_f\in [n]$，使得对每个query $i\in [m]$与key $j\in [n]$有：$f ( q <em>{ i } , k</em> { j_f } ) \geq f ( q <em>{ i } , k</em> { j } )$恒成立，则称该函数族为$\mathbb{K}$与$\mathbb{Q}$的<strong>静态注意力的函数族</strong>。</p>
<p><strong>动态注意力的定义</strong>：已知一个key的集合$\mathbb{K}={k_1,k_2,&hellip;,k_n}\subset \mathbb{R}^d$与query集合$\mathbb{Q}={q_1,q_2,&hellip;,q_m}\subset \mathbb{R}^d$，对于一个打分函数族$\mathcal{F}\subseteq (\mathbb{R}^d\times\mathbb{R}^d \rightarrow \mathbb{R})$，如果对任何的映射$\varphi : [ m ] \rightarrow [ n ]$存在$f\in\mathcal{F}$使得对任何的query $i\in [m]$与key $j_{\neq \varphi(i)}\in [n]$有$f ( q_ { i } , k <em>{\varphi (i)} ) \geq f ( q</em> { i } , k _ { j } )$，则称该函数族为$\mathbb{K}$与$\mathbb{Q}$的<strong>动态注意力的函数族</strong>。</p>
<p>GAT是静态注意力的证明比较简单，大致思路是将计算$e_{ij}$的$\overrightarrow{a}$进行分块：$\overrightarrow{a}=[a_1||a_2]$，则有：</p>
<div>$$
e_{ij} = \text{LeakyReLU} \Big( \overrightarrow{\mathbf{a}}^\top \Big[\mathbf{W} \overrightarrow{h_i}|| \mathbf{W} \overrightarrow{h_j} \Big] \Big)\\
=\text{LeakyReLU} \Big( [a_1||a_2]^\top \Big[\mathbf{W} \overrightarrow{h_i}|| \mathbf{W} \overrightarrow{h_j} \Big] \Big)\\
=\text{LeakyReLU} \Big( [a_1^\top \mathbf{W} h_i+ a_2^\top \mathbf{W} h_j \Big)
$$</div>
证明得到的结论是：$s_j=a_2^\top \mathbf{W} h_j$对于任何的query节点（$h_i$）来说，最大值都是不变的，$s_i=a_1^\top \mathbf{W} h_i$这一项仅仅表征了图像的陡峭程度（如图figure 1a）。
<h4 id="gatv2的动态注意力">GATv2的动态注意力</h4>
<p>GAT之所以会是静态的原因在于$W和a$是连乘的，会坍缩为一个先行层，进行如下的改进：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>公式</th>
</tr>
</thead>
<tbody>
<tr>
<td>GAT</td>
<td>$e(h_i,h_j) = \text{LeakyReLU} \Big( \overrightarrow{\mathbf{a}}^\top \Big[\mathbf{W} \overrightarrow{h_i}||\mathbf{W} \overrightarrow{h_j} \Big] \Big)$</td>
</tr>
<tr>
<td>GATv2</td>
<td>$e(h_i,h_j) = \overrightarrow{\mathbf{a}}^\top\text{LeakyReLU} \Big(\mathbf{W}\Big[ \overrightarrow{h_i}||\overrightarrow{h_j} \Big] \Big)$</td>
</tr>
</tbody>
</table>
<h4 id="如何选择gat与gatv2">如何选择GAT与GATv2</h4>
<p>一般来说很难预先知道两个模型哪个更好，理论上更差的模型可能实际上表现更好，因为可能会产生过拟合等问题，因此作者认为节点之间的交互越复杂那么理论上GATv2会有更好的效果：如果某个问题有全局排序那么GAT可能会好一点，如果不同节点有不同的排序那么GATv2会更好一点。</p>
<p>GAT的作者也是在Twitter上说明了GAT是针对容易过拟合的数据集进行设计的（如cora，citeseer等）。</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Veličković P, Cucurull G, Casanova A, et al. Graph Attention Networks[C]//International Conference on Learning Representations. 2018.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Brody S, Alon U, Yahav E. How attentive are graph attention networks?[J]. arXiv preprint arXiv:2105.14491, 2021.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2022-03-08&nbsp;<a class="git-hash" href="https://github.com/tabuless/myBlog/commit/6cda10e682d244b6c67b11cfe02ef25e867bbad7" target="_blank" title="commit by tabuless(2564801119@qq.com) 6cda10e682d244b6c67b11cfe02ef25e867bbad7: evaluation index">
                                    <i class="fas fa-hashtag fa-fw"></i>6cda10e</a></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/gat_gatv2/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://tabuless.github.io/gat_gatv2/" data-title="GAT&amp;GATv2" data-hashtags="图神经网络"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://tabuless.github.io/gat_gatv2/" data-hashtag="图神经网络"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://tabuless.github.io/gat_gatv2/" data-title="GAT&amp;GATv2"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">图神经网络</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/%E6%97%B6%E5%BA%8F%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%BC%E8%BF%B0/" class="prev" rel="prev" title="时序知识图谱综述"><i class="fas fa-angle-left fa-fw"></i>时序知识图谱综述</a>
            <a href="/tgat/" class="next" rel="next" title="TGAT">TGAT<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="gitalk" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://github.com/gitalk/gitalk"></a>Gitalk</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.92.0">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">tabuless</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.stemmer.support.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.zh.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{"gitalk":{"admin":["tabuless"],"clientID":"b7d8ed424e09262a8719","clientSecret":"5624a7e968dac00542e9b709139cf8ab77fa4602","id":"2022-03-07T22:45:00+08:00","owner":"tabuless","repo":"github_blog_gitalk_repo","title":"GAT\u0026GATv2"}},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"$$","right":"$$"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"},{"display":false,"left":"$","right":"$"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
